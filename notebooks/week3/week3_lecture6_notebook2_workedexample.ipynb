{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming for Biomedical Informatics\n",
    "#### Week 3 - Data Integration & Summary Analysis\n",
    "\n",
    "Using some of the skills we've developed working with eUtils we're now going to take two different lists of genes that use different identifiers convert them to NCBI Gene IDs and then use these to merge the data together. With the final merged data we will do some calculations and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In this script we are going to directly query eUtils using the requests library. This is because it allows us to easily specify the parameters and use the history feature of eUtils to make large queries efficiently.\n",
    "In the code below you should begin to see a pattern for how we approach the mapping process.'''\n",
    "\n",
    "# Preliminaries\n",
    "import urllib.request\n",
    "\n",
    "# we will use this to allow us to search the XML content retutned by the eUtils API\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# load my API key from the file\n",
    "with open('../api_keys/ncbi.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "with open('../api_keys/ncbi_email.txt', 'r') as file:\n",
    "    email = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Load the two lists that we cannot currenly combine\n",
    "\n",
    "'''The first file contains a list of gene symbols\n",
    "\n",
    "e.g.\n",
    "GeneSymbol\n",
    "ADAM10\n",
    "ADAM17\n",
    "APP\n",
    "NAE1\n",
    "APBB1\n",
    "GAPDH\n",
    "BACE1\n",
    "\n",
    "The second file contains a list of RefSeq transcripts (mRNA), and their associated GO terms:\n",
    "\n",
    "e.g.\n",
    "RefSeqID        GOTerm  Description\n",
    "NM_001320570    GO:0003824      catalytic activity\n",
    "NM_001320570    GO:0016787      hydrolase activity\n",
    "NM_001320570    GO:0140096      catalytic activity, acting on a protein\n",
    "NM_001320570    GO:0043226      organelle\n",
    "NM_001320570    GO:0005634      nucleus\n",
    "NM_001320570    GO:0005794      Golgi apparatus\n",
    "\n",
    "We are going to convert Gene Symbols and Refseq IDs to NCBI Gene IDs, and then combine the two lists into a single table.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the gene symbols as a pandas dataframe\n",
    "gene_symbols = pd.read_csv('data/GeneSymbols.tsv', sep='\\t', header=0)\n",
    "\n",
    "# Load the RefSeq data as a pandas dataframe\n",
    "transcript_data = pd.read_csv('data/transcript_functions.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first few rows\n",
    "gene_symbols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first few rows\n",
    "transcript_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2a - Use eSearch to find the internal NCBI ids for the gene symbols\n",
    "# Here we have a list of gene symbols and we want to convert them into gene ids.\n",
    "# First we are going to create a query string that we can use to search the gene database in NCBI.\n",
    "# We will then use the eSearch API to search the gene database and get the gene ids for the gene symbols.\n",
    "\n",
    "# set the database\n",
    "db = 'gene'\n",
    "\n",
    "# convert the gene symbols to a list\n",
    "gene_symbols_list = gene_symbols['GeneSymbol'].tolist()\n",
    "\n",
    "# create a string with where gene_symbols have the [Gene] tag attached and are separated by 'OR'\n",
    "# this is how we can perform long queries using eSearch\n",
    "gene_symbols_query = ' OR '.join([f'{gene}[Gene]' for gene in gene_symbols_list])\n",
    "\n",
    "# be sure to restrict our search so that we get exactly what we intend\n",
    "# add human[Organism] and ( to the start of the string and ) to the end of the string\n",
    "gene_symbols_query = f'(human[Organism]) AND ({gene_symbols_query})'\n",
    "\n",
    "# Define the parameters for the eSearch request\n",
    "# This can be nicely done using a dictionary\n",
    "# Note we include the history feature of eUtils to allow us to make large queries efficiently\n",
    "esearch_params = {\n",
    "    'db': db,\n",
    "    'term': gene_symbols_query,\n",
    "    'api_key': api_key,\n",
    "    'email': email,\n",
    "    'usehistory': 'y'\n",
    "}\n",
    "\n",
    "# encode the parameters so they can be passed to the API\n",
    "encoded_data = urllib.parse.urlencode(esearch_params).encode('utf-8')\n",
    "\n",
    "# the base request url for eSearch\n",
    "url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "\n",
    "# make the request\n",
    "request = urllib.request.Request(url, data=encoded_data)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "# read into an XML object\n",
    "esaerch_data_XML = ET.fromstring(response.read())\n",
    "\n",
    "# Extract WebEnv and QueryKey\n",
    "# Here we use ElementTree to extract the WebEnv and QueryKey from the XML response\n",
    "# We will use these to fetch the gene ids in the next step using eSummary\n",
    "webenv = esaerch_data_XML.find('WebEnv').text\n",
    "query_key = esaerch_data_XML.find('QueryKey').text\n",
    "count = esaerch_data_XML.find('Count').text\n",
    "\n",
    "print('webenv:', webenv, 'query_key:', query_key, 'count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b - Use eSummary to get the gene ids from the internal NCBI ids\n",
    "# Define the parameters for the eSummary request\n",
    "# Note how this is similar to above, but now we don't need to include the search term\n",
    "esummary_params = {\n",
    "    'db': 'gene',\n",
    "    'query_key': query_key,\n",
    "    'WebEnv': webenv,\n",
    "    'api_key': api_key,\n",
    "    'email': email\n",
    "}\n",
    "\n",
    "# encode the parameters so they can be passed to the API\n",
    "encoded_data = urllib.parse.urlencode(esummary_params).encode('utf-8')\n",
    "\n",
    "# the base request url for eSummary\n",
    "url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "\n",
    "# make the request\n",
    "request = urllib.request.Request(url, data=encoded_data)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "#read into an XML object\n",
    "esummary_data_XML = ET.fromstring(response.read())\n",
    "\n",
    "# Extract the gene ids\n",
    "# We are now returning an eSummary XML object that contains the gene ids for the gene symbols we searched for.\n",
    "# Each type of record you return from NCBI can have different XML structure so you often need to print out the XML to see how to extract the information you need.\n",
    "# The best way to do this is to develop the script for a small number of records and then scale up to the full dataset.\n",
    "gene_ids = {}\n",
    "for docsum in esummary_data_XML.findall('DocumentSummarySet/DocumentSummary'):\n",
    "    gene_symbol = docsum.find('Name').text\n",
    "    gene_id = docsum.attrib['uid']\n",
    "    gene_ids[gene_symbol] = gene_id\n",
    "\n",
    "#Â convert the gene_ids dictionary to a pandas dataframe\n",
    "gene_ids_df = pd.DataFrame(gene_ids.items(), columns=['GeneSymbol', 'GeneID'])\n",
    "\n",
    "# look at the first few rows\n",
    "gene_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a - Use eSearch to find the internal NCBI IDd for the RefSeq transcript accessions\n",
    "\n",
    "# get all the refseqids into a list\n",
    "transcript_ids = transcript_data['RefSeqID'].dropna().unique()\n",
    "\n",
    "# create a string with where refseq_ids have the [ACCN] tag attached and are separated by 'OR'\n",
    "# note that this time we are using the RefSeq database ids which are nucleotide entries so we need to modify the query\n",
    "transcript_ids_query = ' OR '.join([f'{transcript_id}[ACCN]' for transcript_id in transcript_ids])\n",
    "\n",
    "# add human[Organism] and ( to the start of the string and ) to the end of the string\n",
    "transcript_ids_query = f'(human[Organism]) AND ({transcript_ids_query})'\n",
    "\n",
    "# Define the parameters for the eSearch request\n",
    "esearch_params = {\n",
    "    'db': 'nucleotide',\n",
    "    'term': transcript_ids_query,\n",
    "    'api_key': api_key,\n",
    "    'email': email,\n",
    "    'usehistory': 'y'\n",
    "}\n",
    "\n",
    "# encode the parameters so they can be passed to the API\n",
    "encoded_data = urllib.parse.urlencode(esearch_params).encode('utf-8')\n",
    "\n",
    "# the base request url for eSearch\n",
    "url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "\n",
    "# make the request\n",
    "request = urllib.request.Request(url, data=encoded_data)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "# read into an XML object\n",
    "esaerch_data_XML = ET.fromstring(response.read())\n",
    "\n",
    "# Extract WebEnv and QueryKey\n",
    "webenv = esaerch_data_XML.find('WebEnv').text\n",
    "query_key = esaerch_data_XML.find('QueryKey').text\n",
    "count = esaerch_data_XML.find('Count').text\n",
    "\n",
    "print('webenv:', webenv, 'query_key:', query_key, 'count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b - Use eSummary to get the internal NCBI ids themselves\n",
    "\n",
    "# Define the parameters for the eSummary request\n",
    "esummary_params = {\n",
    "    'db': 'nucleotide',\n",
    "    'query_key': query_key,\n",
    "    'WebEnv': webenv,\n",
    "    'api_key': api_key,\n",
    "    'email': email\n",
    "}\n",
    "\n",
    "encoded_data = urllib.parse.urlencode(esummary_params).encode('utf-8')\n",
    "\n",
    "url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "\n",
    "request = urllib.request.Request(url, data=encoded_data)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "# read into an XML object\n",
    "esummary_data_XML = ET.fromstring(response.read())\n",
    "\n",
    "# Extract the gene ids\n",
    "transcript_nucleotide_ids = {}\n",
    "for docsum in esummary_data_XML.findall('DocSum'):\n",
    "    gi_id = docsum.find('Id').text\n",
    "    accession = docsum.find('Item[@Name=\"Caption\"]').text\n",
    "    transcript_nucleotide_ids[accession] = gi_id\n",
    "\n",
    "print(transcript_nucleotide_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3c - Use eLink to link the nucleotide ids to the gene ids\n",
    "\n",
    "# NB we are taking advantage of NCBIs internal object linking framework (which include LinkOuts to other databases)\n",
    "# In this case we are wanting to link from the nucleotide database to the gene database\n",
    "\n",
    "'''We have to be careful how we us eLink for mapping. If we pass a list of Ids in a comma separated list it will do the mapping in bulk\n",
    "this means that we will recover all the mappings but just as a list of geneids; we wont know which nucleotide id they are associated with.\n",
    "If we want this 1:1 mapping we have to pass the list of nucleotide ids in the format &id=gi_id1&id=gi_id2&id=gi_id3 rather than &id=gi_id1,gi_id2,gi_id3\n",
    "This way we will get a link explictly for each nucleotide id.\n",
    "'''\n",
    "# create a string where each gi id is preceded by '&id=' and separated by commas\n",
    "elink_search = [f'&id={value}' for key, value in transcript_nucleotide_ids.items()]\n",
    "elink_search = ''.join(elink_search)\n",
    "\n",
    "#use eLink to link the gi ids to the gene ids\n",
    "# Define the parameters for the eLink request\n",
    "# We don't need to use the history feature here as we are only linking a small number of ids\n",
    "elink_params = {\n",
    "    'dbfrom': 'nucleotide',\n",
    "    'db': 'gene',\n",
    "    'api_key': api_key,\n",
    "    'email': email\n",
    "}\n",
    "\n",
    "encoded_data = urllib.parse.urlencode(elink_params).encode('utf-8')\n",
    "\n",
    "#add the elink_search to the end of the encoded_data\n",
    "encoded_data = encoded_data + elink_search.encode('utf-8')\n",
    "\n",
    "# the base request url for eLink\n",
    "url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi\"\n",
    "\n",
    "# make the request\n",
    "request = urllib.request.Request(url, data=encoded_data)\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "# read into an XML object\n",
    "elink_data_XML = ET.fromstring(response.read())\n",
    "\n",
    "# Extract the DbFrom Id element and the DbTo Id element\n",
    "nucleotide2gene_ids = {}\n",
    "\n",
    "# we are going to loop through each LinkSet and extract the nucleotide id and the gene id\n",
    "for linkset in elink_data_XML.findall('LinkSet'):\n",
    "    try:\n",
    "        gi_id = linkset.find('IdList/Id').text\n",
    "        gene_id = linkset.find('LinkSetDb/Link/Id').text\n",
    "        nucleotide2gene_ids[gi_id] = gene_id\n",
    "    except:\n",
    "        pass\n",
    "print(nucleotide2gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Now all the hard work mapping has been done we can begin to combine the data\n",
    "\n",
    "# convert the refseq2nucleotide_ids and transcript2gene_ids to pandas dataframes\n",
    "refseq2nucleotide_ids_df = pd.DataFrame(transcript_nucleotide_ids.items(), columns=['RefSeqID', 'nucleotideID'])\n",
    "transcript2gene_ids_df = pd.DataFrame(nucleotide2gene_ids.items(), columns=['nucleotideID', 'GeneID'])\n",
    "\n",
    "# merge the refseq2nucleotide_ids_df and transcript2gene_ids_df on the nucleotideID column\n",
    "refseq2gene_ids_df = pd.merge(refseq2nucleotide_ids_df, transcript2gene_ids_df, on='nucleotideID')\n",
    "\n",
    "# we now have a table that maps RefSeqIDs to GeneIDs\n",
    "refseq2gene_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Now we can merge the RefSeq meta-data from the very start of the notebook to the gene ids\n",
    "\n",
    "# merge the refseq dataframe with the refseq2gene_ids_df dataframe on the RefSeqID column\n",
    "refseq_gene_ids = pd.merge(refseq, refseq2gene_ids_df, on='RefSeqID')\n",
    "\n",
    "#drop the nucleotideID column\n",
    "refseq_gene_ids = refseq_gene_ids.drop(columns=['nucleotideID'])\n",
    "\n",
    "# we now have a table that maps RefSeqIDs to GeneIDs and contains the meta-data\n",
    "refseq_gene_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Finally we can merge the RefSeq data and the gene symbols data to get our finished table\n",
    "\n",
    "#Â merge the gene_ids_df with the refseq_gene_ids dataframe on the GeneID column\n",
    "combined_df = pd.merge(gene_ids_df, refseq_gene_ids, on='GeneID')\n",
    "\n",
    "# we now have a table that maps GeneSymbols to RefSeqIDs and contains the meta-data\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8 - Summary Analysis\n",
    "\n",
    "# We can do lots of different types of analysis on this data, but here's a few simple examples\n",
    "\n",
    "# use the pivot function in pandas to summarise the number of unique GO terms for each gene symbol sorted by the number of unique GO terms descending\n",
    "gene_summary = combined_df.pivot_table(index='GeneSymbol', values='GOTerm', aggfunc='nunique').sort_values(by='GOTerm', ascending=False)\n",
    "\n",
    "# look at the first few rows\n",
    "gene_summary.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of entries for each class of Description entry\n",
    "description_summary = combined_df['Description'].value_counts()\n",
    "\n",
    "#print the top 10 using PrettyTable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "description_summary_table = PrettyTable()\n",
    "description_summary_table.field_names = ['Description', 'Count']\n",
    "\n",
    "for key, value in description_summary[:10].items():\n",
    "    description_summary_table.add_row([key, value])\n",
    "\n",
    "print(description_summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use numpy to combine the counts for all but the 10 largest classes into a single class called 'Other' for the description_summary dataframe\n",
    "import numpy as np\n",
    "\n",
    "description_summary['Other'] = np.sum(description_summary[10:])\n",
    "\n",
    "# resort the dataframe\n",
    "description_summary = description_summary.sort_values(ascending=False)\n",
    "\n",
    "# drop all but the 11 largest classes\n",
    "description_summary = description_summary[:10]\n",
    "\n",
    "# use PrettyTable to print the top 10 classes\n",
    "description_summary_table = PrettyTable()\n",
    "\n",
    "description_summary_table.field_names = ['Description', 'Count']\n",
    "\n",
    "for key, value in description_summary.items():\n",
    "    description_summary_table.add_row([key, value])\n",
    "\n",
    "print(description_summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the description_summary dataframe as a pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(description_summary, labels=description_summary.index, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
